{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UZYp_Q3zX3oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d753cd-a749-4ade-a748-d16ce1578741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet gradio==3.50.2 openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# Insert your API key Here\n",
        "api_key = \"sk-\"\n",
        "\n",
        "if api_key is None:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable is not set\")\n",
        "\n",
        "def generate_statement(keyword, emotion, action, num, sd):\n",
        "    try:\n",
        "        # Validate the number of sentences\n",
        "        num = int(num)\n",
        "        if num <= 0:\n",
        "            return \"Number of sentences must be a positive integer.\"\n",
        "        elif num > 20:\n",
        "            return \"Number of sentences cannot exceed 20.\"\n",
        "\n",
        "        # Construct a more detailed request message\n",
        "        request_message = f\"\"\"Generate {num} short and meaningful sentences that convey the following:\n",
        "\n",
        "        Context: A statement expressing {emotion} emotion.\n",
        "        Action: {action}\n",
        "        Direction: A statement from {sd}.\n",
        "\n",
        "        Use the keyword(s) '{keyword}' in each sentence. Ensure that the sentences are unique, coherent, and follow proper grammar.\n",
        "        Avoid using pronouns; use nouns instead.\n",
        "\n",
        "        Example: If 'keyword' is 'love,' 'emotion' is 'happiness,' 'action' is 'sharing,' 'num' is 5, and 'sd' is 'me to you,' then a sample output could be:\n",
        "        'Happiness fills my heart as I share my love with you.'\n",
        "\n",
        "        Provide {num} such unique sentences with the sentence number infront of it.\"\"\"\n",
        "\n",
        "        # Initialize the OpenAI API client\n",
        "        openai.api_key = api_key\n",
        "\n",
        "        # Generate text using GPT-2\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-002\",  # GPT-2 engine\n",
        "            prompt=request_message,\n",
        "            max_tokens=1500,  # Adjust max_tokens as needed\n",
        "            n=1  # Number of responses to generate\n",
        "        )\n",
        "\n",
        "        generated_text = response.choices[0].text.strip()\n",
        "        return generated_text\n",
        "\n",
        "    except ValueError:\n",
        "        return \"Number of sentences must be a positive integer.\"\n",
        "\n",
        "\n",
        "def launch_interface():\n",
        "    iface = gr.Interface(\n",
        "        fn=generate_statement,\n",
        "        inputs=[\n",
        "            gr.components.Textbox(label=\"Keyword(s) (Separate by a comma if multiple)\"),\n",
        "            gr.components.Textbox(label=\"Emotion(s) (Separate by a comma if multiple)\"),\n",
        "            gr.components.Textbox(label=\"Action (Optional)\"),\n",
        "            gr.components.Number(label=\"Number of Sentences\"),\n",
        "            gr.components.Radio([\"me to you\", \"me to them\", \"him to them\", \"they to me\"], label=\"Statement Direction\")\n",
        "        ],\n",
        "        outputs=[gr.components.Textbox(label=\"Generated Sentences\")],\n",
        "    )\n",
        "    iface.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "I6VfrUQeX_gA",
        "outputId": "2baaad5e-6a97-46a2-e25c-a9d2701fe54b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://059de0824667ee592d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://059de0824667ee592d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}